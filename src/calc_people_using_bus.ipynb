{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a ratio ofthe cbg's income level to the highest income level, to find how many in that cbg amy use bus - as a percentage of the total number of ODs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gtfs_functions import Feed\n",
    "import numpy as np\n",
    "\n",
    "gtfs_path = '/home/rishav/Programs/routing/data/CARTA_GTFS2024'\n",
    "# Load data\n",
    "income_df = pd.read_csv('/home/rishav/Programs/routing/data/income_tn_all.csv', index_col=0) \n",
    "income_df['estimate'] = income_df['estimate'].astype(float)\n",
    "\n",
    "od_df = pd.read_csv('/home/rishav/Programs/routing/outputs/lodes_2021-01-05_transit_drive2.csv', index_col=0)\n",
    "\n",
    "od_df = od_df[od_df['transit_time'] > od_df['drive_time']]\n",
    "od_df = od_df[od_df['walk_time'] > od_df['drive_time']]\n",
    "od_df = od_df[od_df['walk_time'] >= od_df['transit_time']]\n",
    "\n",
    "# Merge OD data with income data on CBG\n",
    "data = pd.merge(od_df, income_df, left_on='h_geocode', right_on='GEOID', how='left')\n",
    "data = data.dropna(subset='estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_income = income_df['estimate'].max()\n",
    "data['income_ratio'] = data['estimate'] / max_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize travel times\n",
    "data['normalized_drive_time'] = data['drive_time'] / data['drive_time'].max()\n",
    "data['normalized_transit_time'] = data['transit_time'] / data['transit_time'].max()\n",
    "\n",
    "# Assign high penalty to missing bus times\n",
    "high_penalty = 10  # Arbitrary high value; adjust as needed\n",
    "data['normalized_transit_time'].fillna(high_penalty, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights (tune these based on your specific needs or model calibration)\n",
    "income_weight = 0.5\n",
    "transit_time_weight = -0.5  # Negative because shorter times should increase bus usage\n",
    "drive_time_weight = 0.5\n",
    "\n",
    "# Calculate estimated bus usage probability\n",
    "data['bus_usage_probability'] = (\n",
    "    income_weight * data['income_ratio'] +\n",
    "    transit_time_weight * data['normalized_transit_time'] +\n",
    "    drive_time_weight * data['normalized_drive_time']\n",
    ")\n",
    "\n",
    "# Normalize probability to [0, 1] range\n",
    "data['bus_usage_probability'] = (data['bus_usage_probability'] - data['bus_usage_probability'].min()) / (\n",
    "        data['bus_usage_probability'].max() - data['bus_usage_probability'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_count_per_cbg = od_df.groupby('h_geocode').size().reset_index(name='total_od_count')\n",
    "data = pd.merge(data, od_count_per_cbg, on='h_geocode', how='left')\n",
    "data['estimated_bus_users'] = data['bus_usage_probability'] * data['total_od_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.read_csv(f'{gtfs_path}/trips.txt')\n",
    "stop_times_df = pd.read_csv(f'{gtfs_path}/stop_times.txt')\n",
    "stop_times_df = stop_times_df[stop_times_df['departure_time']<'24:00:00']\n",
    "\n",
    "\n",
    "# Convert arrival and departure times to a proper time format if necessary\n",
    "stop_times_df['arrival_time'] = pd.to_datetime(stop_times_df['arrival_time'])\n",
    "stop_times_df['departure_time'] = pd.to_datetime(stop_times_df['departure_time'])\n",
    "\n",
    "# Assume you are interested in a specific time window\n",
    "start_time = pd.to_datetime('06:00:00')\n",
    "end_time = pd.to_datetime('10:00:00')\n",
    "\n",
    "# Filter stop_times for trips that are operating within the time window\n",
    "relevant_trips = stop_times_df[(stop_times_df['arrival_time'] >= start_time) & (stop_times_df['departure_time'] <= end_time)]\n",
    "\n",
    "# Count the number of unique trips operating during this time\n",
    "num_buses = relevant_trips['trip_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge trips data with the relevant trips to get route information\n",
    "route_buses = relevant_trips.merge(trips_df, on='trip_id', how='left')\n",
    "\n",
    "# Count the number of unique trips (buses) for each route\n",
    "num_buses_per_route = route_buses.groupby('route_id')['trip_id'].nunique().reset_index(name='num_buses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the number of buses per route back into your main dataset\n",
    "data = pd.merge(data, num_buses_per_route, left_on='route1', right_on='route_id', how='left')\n",
    "\n",
    "# Fill NaN values for routes without bus service in the time window with 0\n",
    "data['num_buses'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign disability status\n",
    "data['is_disabled'] = np.random.rand(len(data)) < 0.005  # 0.5% probability of being disabled\n",
    "\n",
    "data['bus_capacity'] = 50\n",
    "data['max_bus_capacity'] = data['bus_capacity'] * data['num_buses']\n",
    "data['adjusted_bus_users'] = np.floor(data[['estimated_bus_users', 'max_bus_capacity']].min(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['random_number'] = np.random.rand(len(data))  # Generates a random number between 0 and 1 for each row\n",
    "data['choice'] = np.where(data['random_number'] < data['bus_usage_probability'], 'Bus', 'Car')\n",
    "data['micro_transit_eligible'] = np.where(data['is_disabled'], np.random.rand(len(data)) < 0.3, False)  # 30% of disabled population\n",
    "data['choice'] = np.where(data['micro_transit_eligible'], 'Micro-Transit', data['choice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the existing code for adjusting choices based on bus capacity\n",
    "bus_user_counts = data.groupby([\"route_id\", \"choice\"]).size().unstack(fill_value=0)\n",
    "\n",
    "for route_id, row in bus_user_counts.iterrows():\n",
    "    if row.get(\"Bus\", 0) > data.loc[data[\"route_id\"] == route_id, \"max_bus_capacity\"].values[0]:\n",
    "        # Too many bus users, need to adjust\n",
    "        excess = row[\"Bus\"] - data.loc[data[\"route_id\"] == route_id, \"max_bus_capacity\"].values[0]\n",
    "        bus_users = data[(data[\"route_id\"] == route_id) & (data[\"choice\"] == \"Bus\")]\n",
    "        drop_indices = bus_users.sample(n=int(excess)).index  # Randomly select excess users to switch to 'Car' or 'Micro-Transit'\n",
    "        alternative_choice = np.where(data.loc[drop_indices, 'micro_transit_eligible'], 'Micro-Transit', 'Car')\n",
    "        data.loc[drop_indices, \"choice\"] = alternative_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['choice'] == 'Micro-Transit'].to_csv('outputs/micro-transit_users.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
